---
title: "DATA3888 Group Report"
author: 
  - name: "Shreya Prakash (520496062)"
  - name: "Chenuka (530080640)"
  - name: "Binh Minh Tran (530414672)"
  - name: "Enoch Wong (530531430)"
  - name: "Ruohai (540222281)"
  - name: "Zoha (530526838)"
format:
  html:
    toc: true
    toc_float: true
    toc-depth: 1
    code-fold: true
    code-default: false
    code-summary: "Show Code"
    embed-resources: true
    math: mathjax
editor: visual
jupyter: python3
#bibliography: references.bib
---

``` {python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from itertools import product
from pathlib import Path
import seaborn as sns
from scipy.cluster import hierarchy
from scipy.spatial import distance
import warnings
from pandas.errors import PerformanceWarning

# Suppress fragmentation warnings from pandas
warnings.filterwarnings("ignore", category=PerformanceWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)
```

## 1. Executive Summary

-   Short description of the problem.

-   The main findings.

-   Key figure if appropriate.

-   The practical relevance of the analysis.

## 2. Introduction

2.1 Market importance of RV

2.2 Limitations of traditional models

2.3 Aim & contributions

## 3. Data

``` {python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from itertools import product
import warnings
from pandas.errors import PerformanceWarning
# Suppress fragmentation warnings from pandas
warnings.filterwarnings("ignore", category=PerformanceWarning)
real_volatility = pd.read_csv('real_volatility.csv', index_col=0)
```



3.1 Optiver LOB dataset

3.2 De-normalisation & cleaning



## 4. Methodology

4.1 Feature engineering

4.2 Graph construction & GAT architecture

4.3 Baseline models

To benchmark the performance of the GAT model, diverse baseline models were used including both traditional models and machine learning approaches. Log transformation of volatility was used across all baseline models to stabilise variance and improve model interpretability. These baseline models were served to evaluate whether GAT could capture patterns better than other models.

```{python}
# Define evaluation metrics functions
def metric(prediction, actual):
    prediction, actual = np.array(prediction), np.array(actual)
    eps = 1e-8
    Prediction = np.maximum(prediction, eps)
    Actual = np.maximum(actual, eps)
    RMSE = np.sqrt(np.mean((Prediction - Actual) ** 2))
    QLIKE = np.mean(Actual / Prediction - np.log(Actual / Prediction) - 1)
    RMPSE = np.sqrt(np.mean(np.square((actual - prediction) / actual))) * 100
    MAPE = np.mean(np.abs((actual - prediction) / actual)) * 100
    return RMSE, QLIKE, RMPSE, MAPE
```

### HAR-RV
``` {python, warning=false}
# lists to store result
har_panel = pd.DataFrame()
RMSE_list = []
QLIKE_list = []
RMPSE_list = []
MAPE_list = []
# Dictionary to store best parameters for each stock
best_params_dict = {}

# Hyperparameter Tuning
lag_matrix = {
    'short': [1],
    'medium': [5, 7],
    'long': [22, 30]
}

lag_matrix = list(product(lag_matrix['short'], lag_matrix['medium'], lag_matrix['long']))

# go through each unique stock
for stock in real_volatility.columns:  
    stock_series = real_volatility[stock]

    # Initialise the best performance tracker
    final_MAPE = float('inf')
    final_Prediction = None
    final_Actual = None
    best_params = None  

    # Grid Search each combination
    for short, medium, long in lag_matrix:
        har_data = pd.DataFrame({'volatility': stock_series})      
        har_data['rv_short'] = stock_series.shift(short)
        har_data['rv_medium'] = stock_series.rolling(window=medium).mean().shift(1)
        har_data['rv_long'] = stock_series.rolling(window=long).mean().shift(1)
        har_data['trend'] = np.arange(len(stock_series))
        har_data = har_data.dropna()

        # Train-Validation-Test split
        number = len(har_data)
        train_size = int(number * 0.8)
        validation_size = int(number * 0.1)

        har_train = har_data.iloc[:train_size]
        har_validation = har_data.iloc[train_size:train_size + validation_size]
        har_test = har_data.iloc[train_size + validation_size:]

        feature_columns = ['rv_short', 'rv_medium', 'rv_long', 'trend']
        
        # Prepare the dataset 
        train_X = har_train[feature_columns]
        train_y = har_train['volatility']
        validation_X = har_validation[feature_columns]
        validation_y = har_validation['volatility']
        if train_X.empty or validation_X.empty:
            print(f"Skipping {stock} with lags (short:{short}, medium:{medium}, long:{long}) due to insufficient data.")
            continue

        # fit the linear model
        har_model = LinearRegression()
        har_model.fit(train_X, train_y)

        # evaluate on the validation set
        validation_Prediction = np.exp(har_model.predict(validation_X))
        validation_Actual = np.exp(validation_y)
        validation_RMSE, validation_QLIKE, validation_RMPSE, validation_MAPE = metric(validation_Prediction, validation_Actual)

        # check if this the best lag combination
        if validation_MAPE < final_MAPE:
            final_MAPE = validation_MAPE
            test_features = har_test[feature_columns]
            test_target = har_test['volatility']
            
            valid_index = test_features.dropna().index
            test_X = test_features.loc[valid_index]
            test_y = test_target.loc[valid_index]

            # evaluate on the test set
            final_Prediction = np.exp(har_model.predict(test_X))
            final_Actual = np.exp(test_y)
            
            # Store best parameters for this stock
            best_params = {'short': short, 'medium': medium, 'long': long}

    # Store Result
    if final_Prediction is not None:
        har_panel[stock] = pd.Series(final_Prediction, index=valid_index)
```
- Predicts volatility using lagged realized volatility over different time periods  
- Captures long memory in volatility patterns  
- **Hyperparameters Tuning:** 
  - **Short:** 1, 
  - **Midium:** average of 5 and 7, 
  - **Long:** the average of 22 and 30
- **Result ( Most Common):** **Short**= 1, **Midium**= 5, **Long**= 30


### Lag-Model
``` {python, warning=false, echo=false} 
# lists to store the value
lag_panel = pd.DataFrame()
RMSE_list = []
QLIKE_list = []
RMPSE_list = []
MAPE_list = []
# Dictionary to store best lag parameter for each stock
best_lag_dict = {}

# Hyperparameter tuni
# ng
Lag = [1, 2, 3, 4, 5]

# Go through each stock
for stock in real_volatility.columns:  
    stock_series = real_volatility[stock]

    # Initialise for the best performance tracker
    final_MAPE = float('inf')
    final_Prediction = None
    final_Actual = None
    final_index = None
    best_lag = None  

    # go through each lag threshold
    for lag in Lag:
        
        # feature set
        lag_data = pd.DataFrame({
            'volatility': stock_series,
            'lag': stock_series.shift(lag),
            'trend': np.arange(len(stock_series))})
        lag_data = lag_data.dropna()

        # Train-Validation-Test split
        number = len(lag_data)
        train_size = int(number * 0.8)
        validation_size = int(number * 0.1)

        lag_train = lag_data.iloc[:train_size]
        lag_Validation = lag_data.iloc[train_size:train_size + validation_size]
        lag_test = lag_data.iloc[train_size + validation_size:]

        # Prepare the dataset
        feature_columns = ['lag', 'trend']
        train_X = lag_train[feature_columns]
        train_y = lag_train['volatility']
        validation_X = lag_Validation[feature_columns]
        validation_y = lag_Validation['volatility']
        test_X = lag_test[feature_columns]
        test_y = lag_test['volatility']
        test_X = test_X.dropna()
        test_y = test_y.loc[test_X.index]

        # fit the model
        lag_model = LinearRegression()
        lag_model.fit(train_X, train_y)

        # evaluate on the validation set
        validation_Prediction = np.exp(lag_model.predict(validation_X))
        validation_Actual = np.exp(validation_y)
        validation_RMSE, validation_QLIKE, validation_RMPSE, validation_MAPE = metric(validation_Prediction, validation_Actual)

        # Check is it the best performance
        if validation_MAPE < final_MAPE:
            final_MAPE = validation_MAPE
            final_Prediction = np.exp(lag_model.predict(test_X))
            final_Actual = np.exp(test_y)
            final_index = test_X.index
            best_lag = lag  # Store the best lag

    # store the result
    if final_Prediction is not None:
        lag_panel[stock] = pd.Series(final_Prediction, index=final_index)  
```
- Used only the recent volatility to predict volatility
- Served as a benchmark and captured short-term correlation
- **Hyperparameters Tuning:** Lag periods [1, 2, 3, 4, 5]
- **Features:** Lagged volatility values, time trend
- **Result (Most Common):** lag = 1 (100%)

### PCA Model 
``` {python}
# List to store value
pca_linear_panel = pd.DataFrame()
RMSE_list = []
QLIKE_list = []
RMPSE_list = []
MAPE_list = []
# Dictionary to store best variance threshold for each stock
best_variance_dict = {}

# Hyperparameters tuning
variance_threshold = [0.9, 0.93, 0.95, 0.97, 0.99]

# Go through each individual stock
for stock in real_volatility.columns:  
    stock_series = real_volatility[stock]

    # feature set
    pca_data = pd.DataFrame({
        'volatility': stock_series,
        'trend': np.arange(len(stock_series)),
        'lag1': stock_series.shift(1),
        'lag2': stock_series.shift(2),
        'lag3': stock_series.shift(3),
        'moving_avg_3': stock_series.rolling(window=3).mean().shift(1),
        'moving_avg_5': stock_series.rolling(window=5).mean().shift(1),
        'moving_avg_10': stock_series.rolling(window=10).mean().shift(1),
        'std_5': stock_series.rolling(window=5).std().shift(1),
        'std_10': stock_series.rolling(window=10).std().shift(1)})

    pca_data = pca_data.dropna()

    # Train-Validation-Test split
    number = len(pca_data)
    train_size = int(number * 0.8)
    validation_size = int(number * 0.1)

    pca_train = pca_data.iloc[:train_size]
    pca_validation = pca_data.iloc[train_size:train_size + validation_size]
    pca_test = pca_data.iloc[train_size + validation_size:]

    # Prepare the dataset 
    feature_columns = ['trend', 'lag1', 'lag2', 'lag3', 'moving_avg_3', 'moving_avg_5', 'moving_avg_10', 'std_5', 'std_10']
    
    train_X = pca_train[feature_columns]
    train_y = pca_train['volatility']
    validation_X = pca_validation[feature_columns]
    validation_y = pca_validation['volatility']
    test_X = pca_test[feature_columns]
    test_y = pca_test['volatility']

    # Scaling
    scaler = StandardScaler()
    train_X_scaled = scaler.fit_transform(train_X)
    validation_X_scaled = scaler.transform(validation_X)
    test_X_scaled = scaler.transform(test_X)

    # Initialise for the best performance tracker
    final_MAPE = float('inf')
    final_Prediction = None
    final_Actual = None
    final_variance = None

    # Go through each variance threshold
    for variance in variance_threshold:  
        pca = PCA(n_components=variance)     
        train_pca = pca.fit_transform(train_X_scaled)
        validation_pca = pca.transform(validation_X_scaled)

        pca_linear_model = LinearRegression()
        pca_linear_model.fit(train_pca, train_y)

        validation_Prediction = np.exp(pca_linear_model.predict(validation_pca))
        validation_Actual = np.exp(validation_y)
        validation_RMSE, validation_QLIKE, validation_RMPSE, validation_MAPE = metric(validation_Prediction, validation_Actual)

        # check if this is the best variance 
        if validation_MAPE < final_MAPE:
            final_MAPE = validation_MAPE
            final_variance = variance
            final_model = pca_linear_model
            final_pca = pca
        
    # evaluate on test set    
    test_pca = final_pca.transform(test_X_scaled)
    test_prediction = final_model.predict(test_pca)
    final_Prediction = np.exp(test_prediction)
    final_Actual = np.exp(test_y)
    pca_linear_panel[stock] = pd.Series(final_Prediction, index=pca_test.index)

```
- simplified the data by reducing noise and dimensionality then applied linear regression 
- help the model to focus on the most informative component of the data
- **Hyperparameters Tuning:** Variance threshold [0.9, 0.93, 0.95, 0.97, 0.99]
- **Features:** Time trends, lag terms (lag1-3), moving averages (3, 5, 10 ), standard deviations (5, 10)
- **Result (Most Common):** 0.99 threshold


### Random Forest
``` {python}
#| eval: false
#| echo: false
rf_panel = pd.DataFrame()
RMSE_list = []
QLIKE_list = []
RMPSE_list = []
MAPE_list = []
# Dictionary to store best n_estimators for each stock
best_estimators_dict = {}

n_estimators = [200, 300, 500]

for stock in real_volatility.columns:  
    stock_series = real_volatility[stock]

    rf_data = pd.DataFrame({
        'volatility': stock_series,
        'trend': np.arange(len(stock_series)),
        'lag1': stock_series.shift(1),
        'lag2': stock_series.shift(2),
        'lag3': stock_series.shift(3),
        'moving_avg_3': stock_series.rolling(window=3).mean().shift(1),
        'moving_avg_5': stock_series.rolling(window=5).mean().shift(1),
        'moving_avg_10': stock_series.rolling(window=10).mean().shift(1),
        'std_5': stock_series.rolling(window=5).std().shift(1),
        'std_10': stock_series.rolling(window=10).std().shift(1),
        'max_5': stock_series.rolling(window=5).max().shift(1),
        'min_5': stock_series.rolling(window=5).min().shift(1)})

    rf_data = rf_data.dropna()

    number = len(rf_data)
    train_size = int(number * 0.8)
    validation_size = int(number * 0.1)

    rf_train = rf_data.iloc[:train_size]
    rf_validation = rf_data.iloc[train_size:train_size + validation_size]
    rf_test = rf_data.iloc[train_size + validation_size:]

    feature_columns = ['trend', 'lag1', 'lag2', 'lag3', 'moving_avg_3', 'moving_avg_5', 'moving_avg_10', 'std_5', 'std_10', 'max_5', 'min_5']
    
    train_X = rf_train[feature_columns]
    train_y = rf_train['volatility']
    validation_X = rf_validation[feature_columns]
    validation_y = rf_validation['volatility']
    test_X = rf_test[feature_columns]
    test_y = rf_test['volatility']

    final_MAPE = float('inf')
    final_Prediction = None
    final_Actual = None
    best_n = None  # Track best n_estimators

    for n in n_estimators:
        rf_model = RandomForestRegressor(n_estimators=n, random_state=42, max_depth=10)
        rf_model.fit(train_X, train_y)
        validation_Prediction = np.exp(rf_model.predict(validation_X))
        validation_Actual = np.exp(validation_y)
        validation_RMSE, validation_QLIKE, validation_RMPSE, validation_MAPE = metric(validation_Prediction, validation_Actual)

        if validation_MAPE < final_MAPE:
            final_MAPE = validation_MAPE
            final_Prediction = np.exp(rf_model.predict(test_X))
            final_Actual = np.exp(test_y)
            best_n = n  # Store best n_estimators

    rf_panel[stock] = pd.Series(final_Prediction, index=rf_test.index)


```
- Built multiple decision trees and averaged the result
- Could handled non-linear relationship and was suitable for data with multiple features (common in stock data)
- **Hyperparameters Tuning:** Depth = 10 (fixed), n_estimators [200, 300, 500]
- **Features:** Trend, lags, moving averages, standard deviations, extrema (11 total)
- **Result (Most Common):** estimators = 200



### Gradient Boosting
``` {python}
#| eval: false
#| echo: false
gb_panel = pd.DataFrame()
RMSE_list = []
QLIKE_list = []
RMPSE_list = []
MAPE_list = []
# Dictionary to store best learning rate for each stock
best_lr_dict = {}

learning_rate = [0.01, 0.05, 0.1]

for stock in real_volatility.columns:  
    stock_series = real_volatility[stock]

    gb_data = pd.DataFrame({
        'volatility': stock_series,
        'trend': np.arange(len(stock_series)),
        'lag1': stock_series.shift(1),
        'lag2': stock_series.shift(2),
        'lag3': stock_series.shift(3),
        'moving_avg_3': stock_series.rolling(window=3).mean().shift(1),
        'moving_avg_5': stock_series.rolling(window=5).mean().shift(1),
        'moving_avg_10': stock_series.rolling(window=10).mean().shift(1),
        'std_5': stock_series.rolling(window=5).std().shift(1),
        'std_10': stock_series.rolling(window=10).std().shift(1),
        'max_5': stock_series.rolling(window=5).max().shift(1),
        'min_5': stock_series.rolling(window=5).min().shift(1)})

    gb_data = gb_data.dropna()

    number = len(gb_data)
    train_size = int(number * 0.8)
    validation_size = int(number * 0.1)

    gb_train = gb_data.iloc[:train_size]
    gb_validation = gb_data.iloc[train_size:train_size + validation_size]
    gb_test = gb_data.iloc[train_size + validation_size:]

    feature_columns = ['trend', 'lag1', 'lag2', 'lag3', 'moving_avg_3', 'moving_avg_5', 'moving_avg_10', 'std_5', 'std_10', 'max_5', 'min_5']
    
    train_X = gb_train[feature_columns]
    train_y = gb_train['volatility']
    validation_X = gb_validation[feature_columns]
    validation_y = gb_validation['volatility']
    test_X = gb_test[feature_columns]
    test_y = gb_test['volatility']

    final_MAPE = float('inf')
    final_Prediction = None
    final_Actual = None
    best_lr = None  # Track best learning rate

    for learning in learning_rate:
        gb_model = GradientBoostingRegressor(n_estimators=500, learning_rate=learning, max_depth=6, random_state=42)
        gb_model.fit(train_X, train_y)
        validation_Prediction = np.exp(gb_model.predict(validation_X))
        validation_Actual = np.exp(validation_y)
        validation_RMSE, validation_QLIKE, validation_RMPSE, validation_MAPE = metric(validation_Prediction, validation_Actual)

        if validation_MAPE < final_MAPE:
            final_MAPE = validation_MAPE
            final_Prediction = np.exp(gb_model.predict(test_X))
            final_Actual = np.exp(test_y)
            best_lr = learning  # Store best learning rate

    gb_panel[stock] = pd.Series(final_Prediction, index=gb_test.index)
```
- Built multiple trees
- Each new tree would correct the error of the previous tree
- Evaluated the performance of error-reduction
- **Hyperparameters Tuning:** Learning rate [0.01, 0.05, 0.1], n_estimators = 500, max_depth = 6 (fixed)
- **Features:** Trend, lags, moving averages, standard deviations, extrema (11 total)
- **Results (Most Common):** learning rate = 0.01

### Linear Regression
``` {python}
# List to store value
linear_panel = pd.DataFrame()
RMSE_list = []
QLIKE_list = []
RMPSE_list = []
MAPE_list = []
# Dictionary to store best moving average for each stock
best_ma_dict = {}

# Hyperparameters tuning
moving_average = [3, 5, 7, 10]

# go through each stock
for stock in real_volatility.columns:  
    stock_series = real_volatility[stock]

    # initialise for the best performance tracker
    final_MAPE = float('inf')
    final_Prediction = None
    final_Actual = None
    best_ma = None  # Track best moving average window

    # go through each moving average threshold
    for moving in moving_average: 

        # feature sets
        linear_data = pd.DataFrame({
            'volatility': stock_series,
            'trend': np.arange(len(stock_series)),
            'lag1': stock_series.shift(1),
            'lag2': stock_series.shift(2),
            'moving_avg': stock_series.rolling(window=moving).mean().shift(1)})
        linear_data = linear_data.dropna()

        # Train-Validation-Test split
        number = len(linear_data)
        train_size = int(number * 0.8)
        validation_size = int(number * 0.1)

        linear_train = linear_data.iloc[:train_size]
        linear_validation = linear_data.iloc[train_size:train_size + validation_size]
        linear_test = linear_data.iloc[train_size + validation_size:]

        # Prepare the dataset 
        feature_columns = ['trend', 'lag1', 'lag2', 'moving_avg']
        train_X = linear_train[feature_columns]
        train_y = linear_train['volatility']
        validation_X = linear_validation[feature_columns]
        validation_y = linear_validation['volatility']


        # fit on train set
        linear_model = LinearRegression()
        linear_model.fit(train_X, train_y)

        # evaluate on the validation set
        validation_Prediction = np.exp(linear_model.predict(validation_X))
        validation_Actual = np.exp(validation_y)
        validation_RMSE, validation_QLIKE, validation_RMPSE, validation_MAPE = metric(validation_Prediction, validation_Actual)

        # check is this the best
        if validation_MAPE < final_MAPE:
            final_MAPE = validation_MAPE
            test_data = linear_test.dropna(subset=feature_columns + ['volatility'])
            test_X = test_data[feature_columns]
            test_y = test_data['volatility'] 
            final_Prediction = np.exp(linear_model.predict(test_X))
            final_Actual = np.exp(test_y)
            best_ma = moving  # Store the best moving average
            

    # store the value for each stock
    if final_Prediction is not None:
        linear_panel[stock] = pd.Series(final_Prediction, index=test_X.index)
```
- Evaluated the performance of linear relationship between features and targets
- Evaluated whether there are trends in the data
- **Hyperparameters Tuning:** Moving average window sizes [3, 5, 7, 10]
- **Features:** Time trend, lag1, lag2, moving average
- **Result (Most Common):** 5 windows 




# FOR NOW RANDOM FOREST AND GRADIENT BOOSTING HAVE BEEN TAKEN OUT, MUST INCLUDE IT
```{python}
#| eval: false
#| echo: false

import os
from pathlib import Path

# Use current directory as save path
save_path = Path('.')

# All model panels
models_panels = {
    'LAG': lag_panel,
    'HAR_RV': har_panel, 
    'Linear': linear_panel,
    'PCA_Linear': pca_linear_panel
    #'Random_Forest': rf_panel,
    #'Gradient_Boosting': gb_panel
}

# 1. Save all model panels to CSV
for model_name, panel in models_panels.items():
    filename = f"{model_name}_predictions.csv"
    filepath = save_path / filename
    panel.to_csv(filepath)
```

4.4 Evaluation protocol & metrics

The evaluation metrics that are used for both the GAT model and baseline model to evaluate the performance of the GAT model in capturing complex inter-stock relationships.

### Root Mean Squared Percentage Error (RMSPE)
- Measure the average squared difference between prediction and actual values in percentage format
- It is scale-independent means it would provide comparable results across different size of datasets
$$
\text{RMSPE} = \sqrt{ \frac{1}{n} \sum_{t=1}^n \left( \frac{y_t - \hat{y}_t}{y_t} \right)^2 }
$$


### Quantile Likelihood (QLIKE)
- Assess the quality of volatility scale estimation by penalising mis-estimation of variance
- It is sensitive to risk
$$
\text{QLIKE} = \frac{1}{n} \sum_{t=1}^n \left( \frac{y_t}{\hat{y}_t} - \log \left( \frac{y_t}{\hat{y}_t} \right) - 1 \right)
$$


### Mean Absolute Percentage Error (MAPE) 
- Measure the average difference between prediction and actual values in percentage format
- It is easy to interpret and it is scale-independent
$$
\text{MAPE} = \frac{1}{n} \sum_{t=1}^n \left| \frac{y_t - \hat{y}_t}{y_t} \right|
$$
## Data-Splitting 

For each individual stock, it would split the dataset into 80% training, 10% validation and 10% testing. The training set was used to fit the model. The validation set was used for hyperparameters tuning while the test set was used to evaluate the final performance. This walk-forward split ensures that the future information would not leak into the past, maintaining data integrity. 



## 5. Results
5.1 Overall performance
```{python}

#| label: tbl-performance
#| tbl-cap: "Performance metrics across all stocks for each model."
#| tbl-align: center
#| 
model_names = ['HAR_RV', 'LAG', 'Linear', 'PCA_Linear', 'Random_Forest', 'Gradient_Boosting']

desktop_path = Path('.')

# Calculate performance metrics for each model
def calculate_performance_metrics():
    
    metrics = []

    for model in model_names:

        y_pred = pd.read_csv(f'{model}_predictions.csv', index_col=0)
            
        actual = pd.read_csv('real_volatility.csv')
        y_true = actual.reindex(index=y_pred.index) 

        Y, Ŷ = np.exp(y_true.values), y_pred.values
        eps = 1e-12

        rmspe = np.sqrt(np.mean(((Ŷ - Y) / (Y + eps))**2, axis=0))
        ratio = (Y + eps) / (Ŷ + eps)
        qlike = np.mean(ratio - np.log(ratio) - 1, axis=0)
        mape = np.mean(np.abs(Ŷ - Y) / (Y + eps), axis=0)
        rmse = np.sqrt(np.mean((Ŷ - Y)**2, axis=0))

        for stock, RMSE, RMSPE, QLIKE, MAPE in zip(y_true.columns, rmse, rmspe, qlike, mape):
            metrics.append({
                "Model": model,
                "Stock": stock,
                "RMSE": RMSE,
                "RMSPE": RMSPE,
                "QLIKE": QLIKE,
                "MAPE": MAPE
            })

    summary_df = pd.DataFrame(metrics)
    summary_df1 = summary_df.groupby("Model")[["RMSE", "RMSPE", "QLIKE", "MAPE"]].mean().round({
        "RMSE": 6,
        "RMSPE": 2,
        "QLIKE": 6,
        "MAPE": 2
    })

    return summary_df1
    
# Run the code
calculate_performance_metrics()
```
We assess the Graph Attention Network model on the test set using standard volatility forecasting metrics: Root Mean Squared Percentage Error (RMSPE), Mean Absolute Percentage Error (MAPE), and QLIKE loss. RMSPE is the main metric, while QLIKE penalizes under-prediction of variance. Lower values across all metrics indicate better accuracy.

The cross-sectional evaluation shows clear performance differences among models. GAT outperforms other models across all metrics: RMSE of 0.600356, QLIKE of 0.041425, MAPE of 22.48, and RMSPE of 34.40, as shown in the performance table.

Traditional models exhibit competitive performance: PCA_Linear is best among traditional methods (RMSE: 0.956301, RMSPE: 0.54, QLIKE: 0.178410, MAPE: 0.40), followed by Random_Forest (RMSE: 0.960064, RMSPE: 0.59) and HAR_RV (RMSE: 0.964477, RMSPE: 0.63). The Linear model is as good (RMSE: 0.977705), whereas LAG model is worst with the highest error measures (RMSE: 1.016574, RMSPE: 0.77).

Machine learning method have mixed performances: Random_Forest is a bit better than Gradient_Boosting on almost every measure. However, Gradient_Boosting performs acceptably (RMSE: 0.983840, RMSPE: 0.65, MAPE: 0.47) but cannot surpass the less complex PCA_Linear algorithm.

These findings point to GAT's better performance in capturing complicated volatility structures, with PCA_Linear being the best performing conventional method.


5.2 Error analysis & regime split

```{python}
#| label: fig-model-comparison
#| fig-cap: "Predicted vs Actual Volatility for Different Models"
#| fig-align: center

model_names = ['HAR_RV', 'LAG', 'Linear', 'PCA_Linear', 'Random_Forest', 'Gradient_Boosting', 'GAT']
desktop_path = Path('.')

def load_and_align_data():
    model_preds = {}
    shared_stocks = None
    shared_dates = None

    # Load all models
    for model in model_names:
        if model == 'GAT':
            preds = pd.read_csv('GAT_prediction_panel.csv', index_col=0)
        else:
            preds = pd.read_csv(f'{model}_predictions.csv', index_col=0)
        
        model_preds[model] = preds
        
        if shared_stocks is None:
            actual = pd.read_csv('real_volatility.csv')
            shared_stocks = list(set(preds.columns).intersection(set(actual.columns)))
            shared_dates = preds.index.tolist()
        else:
            shared_stocks = list(set(shared_stocks).intersection(set(preds.columns)))
            shared_dates = list(set(shared_dates).intersection(set(preds.index.tolist())))

    aligned_actual = actual.reindex(index=shared_dates)
    aligned_actual1 = np.exp(aligned_actual)
    
    return model_preds, aligned_actual1, shared_stocks, shared_dates

def create_comparison_plots():
    model_preds, actual, shared_stocks, shared_dates = load_and_align_data()
    
    plt.style.use('ggplot')
    colors = ["#0707E7", "#FB7D07", "#15F115", "#F40808", "#8518EA", '#8C564B', "#ED09A8"]
    
    fig, axes = plt.subplots(2, 4, figsize=(14, 8))
    axes = axes.flatten()
    
    # Calculate average across stocks
    avg_actual = actual.loc[shared_dates, shared_stocks].mean(axis=1).values
    x_indices = np.arange(len(avg_actual))
    model_errors = {}
    
    for idx, model in enumerate(model_names):
        if idx >= len(axes) - 1:
            break
            
        # Get model predictions and calculate average
        model_data = model_preds[model].loc[shared_dates, shared_stocks]
        avg_pred = model_data.mean(axis=1).values
        
        
        # Store errors for boxplot
        errors = np.abs(avg_pred - avg_actual)
        model_errors[model] = errors
        
        # Plot
        axes[idx].plot(x_indices, avg_actual, '-', color='#030202', 
                      linewidth=1.5, label='Actual', alpha=0.8)
        axes[idx].plot(x_indices, avg_pred, '-', color=colors[idx % len(colors)], 
                      linewidth=1.2, label=model, alpha=0.8)
        
        
        axes[idx].set_xlabel('Time Index')
        axes[idx].set_ylabel('Avg Volatility')
        axes[idx].legend(loc='upper right')
        axes[idx].grid(True, linestyle='--', alpha=0.6)
    
    # Error distribution boxplot
    if model_errors:
        boxplot_data = [errors for errors in model_errors.values()]
        boxplot = axes[-1].boxplot(boxplot_data, patch_artist=True)
        
        for i, box in enumerate(boxplot['boxes']):
            box.set(facecolor=colors[i % len(colors)], alpha=0.6)
        
        axes[-1].set_title('Error Distribution')
        axes[-1].set_ylabel('Absolute Error')
        axes[-1].set_xticklabels(model_errors.keys(), rotation=45, ha='right')
        axes[-1].grid(True, linestyle='--', alpha=0.6)
    
    plt.suptitle('Model Predictions vs Actual Values', fontsize=14, y=0.98, fontweight='bold')
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.show()

# Run the code
create_comparison_plots()
```
The Graph Attention Transformer (GAT) model exhibits significant forecast errors predominantly during periods of abrupt volatility spikes and the subsequent brief reversals. As depicted in @fig-model-comparison, the empirical realizations of realized volatility (RV), represented by the black line, experience sharp surges during market shock events. In contrast, the GAT’s predictions, illustrated by the magenta line, demonstrate a notable lag in response to the initial volatility spike, followed by a brief overshoot as the market reverts to normalized volatility levels. This predictive lag and overshoot can be attributed to the model's reliance on lagged features and its intrinsic tendency to smooth noise.

In the top-decile volatility regime, this pattern of under-prediction followed by over-prediction contributes to a tangible increase in Root Mean Square Error (RMSE). However, it is worth noting that, even in these extreme conditions, the GAT model outperforms all benchmark methods.

In less volatile conditions, the model maintains a tight fit, with fluctuations exhibiting minimal residuals. This consistency is quantified by an overall test Root Mean Square Error (RMSE) of 0.600356, as indicated in the figure title. It is evident that the majority of prediction error is concentrated within a limited number of spike windows. 

All baseline models underpredict during volatility spike as seen in @fig-model-comparison. Among all models, HAR-RV and PCA are more consistent in tracking overall volatility level and less sensitive to outliers compared with Random Forest and Gradient Boosting. 

In low-volatility periods, the majority of baseline models are able to capture the pattern with minimal error. However during high volatility periods, simple models like the Lag model fail to adjust quickly and result in larger error.

Moreover, HAR-RV performs better as it can adjust quickly across different regimes. This suggested that the model’s structure is better in responding to changing conditions. In contrast, RF and GB struggled with adjusting which indicates that further hyperparameters tuning and feature adjustments are required to improve the model’s adaptability in changing market conditions. 


5.3 Interpretability

``` {python}
#| label: fig-correlation
#| fig-cap: "Heatmap of inter-stock correlations"
#| fig-align: center
desktop_path = Path('.')

def visualize_stock_correlation():
    # Load data
    volatility_data = pd.read_csv('real_volatility.csv', index_col=0)

    correlation_matrix = volatility_data.corr()
    
    # Perform clustering to select 
    dist = distance.squareform(1 - correlation_matrix.abs())
    linkage = hierarchy.linkage(dist, method='ward')
    clusters = hierarchy.fcluster(linkage, 5, criterion='maxclust')
    
    # Select stocks from each cluster 
    selected_stocks = []
    for cluster_id in range(1, max(clusters)+1):
        cluster_stocks = [stock for i, stock in enumerate(correlation_matrix.index) if clusters[i] == cluster_id]
        selected_stocks.extend(cluster_stocks[:6])  
    
    if len(selected_stocks) > 30:
        selected_stocks = selected_stocks[:30]
    
    subset_corr = correlation_matrix.loc[selected_stocks, selected_stocks]
    
    # Create correlation heatmap
    plt.figure(figsize=(10, 8))
    mask = np.triu(np.ones_like(subset_corr, dtype=bool))
    sns.heatmap(subset_corr, cmap='RdBu_r', vmin=-0.2, vmax=1.0, 
                center=0.5, annot=True, fmt='.2f', linewidths=0.5, mask=mask)
    plt.title('Stock Correlation Heatmap (5 Clusters)')
    
    plt.tight_layout()
    plt.show()


# Run the code
visualize_stock_correlation()
```

Linear models such as HAR-RV and Linear Regression are the most interpretable across all baseline models. These models rely on the assumption of simple linear relationship and clear coefficients that represent a direct relationship between input and output. This is extremely useful for understanding how lagged volatility can directly influence the prediction.

The PCA model transforms to reduce dimensionality and noise but this transformation reduces the interpretability. The components do not have direct corresponding with the original feature, making it harder to explain.

Tree-based models like Random Forest and Gradient Boosting offer powerful predictive ability as it could capture non-linear relationship and complex interaction. However, this leads to difficulty to interpret.

Overall, HAR-RV offers the best balance between accuracy and interpretability. It offers a simple linear relationship while multiple time periods allow the model to adapt well across different regimes. 

The Graph Attention Network (GAT) distinguishes itself from traditional baseline models by inherently integrating interpretability into its design. Each edge within the GAT framework possesses an attention coefficient, denoted as \( \alpha_{ij} \), which quantifies the degree of influence that stock \( j \) has on the forecast of stock \( i \). By averaging these coefficients across the test set, we can construct the influence matrix, as depicted in @fig-correlation. 

The correlation between the bright blocks within this matrix and the empirical volatility-correlation blocks shown in the left-hand heatmap suggests that the network has effectively learned to prioritize information from economically related peers—those stocks that share the same sector or common risk factors—while diminishing the impact of weakly connected stocks. 

This characteristic serves to make the GAT, despite being a non-linear deep learning model, a bastion of transparency. The prediction process is driven primarily by a localized neighbourhood of highly correlated stocks, allowing us to directly interpret the contributions through \( \alpha_{ij} \). Consequently, we can articulate a cohesive narrative: "Tech stocks predominantly respond to movements in other tech stocks, while financial stocks are more attuned to their financial counterparts." This capability underscores the GAT's strength in capturing intricate cross-stock interactions that simpler linear models or tree-based approaches tend to overlook.




## 6. Project Deployment & Interdisciplinary Impact

6.1 Shiny app demo

6.2 Real-time simulation

## 7. Discussion

7.1 Key findings

7.2 Limitations

7.3 Future work

## 8. Conclusion

## 9. Student Contribution

## 10. References

## 11. Appendix

11.1 Code Snippets

11.2 Full Metrics Table


11.3 Instructions to run/ environment details
